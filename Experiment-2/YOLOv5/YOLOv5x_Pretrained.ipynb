{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "633M0FF4Hmc5",
        "outputId": "dbef2739-68ac-460c-b59f-93bcb6b49b3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9aVJV318hhg5"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "import torch\n",
        "import glob\n",
        "\n",
        "# Fix a seed for PyTorch\n",
        "torch.manual_seed(4200);\n",
        "\n",
        "## Enable GPU\n",
        "\n",
        "gpu = True\n",
        "\n",
        "if gpu == True:\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xuj3xzD-3yJy",
        "outputId": "0d105fa2-eb18-46cc-a48a-e261d94697a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2022.12.7 (from roboflow)\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Collecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (8.4.0)\n",
            "Collecting pyparsing==2.4.7 (from roboflow)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Collecting supervision (from roboflow)\n",
            "  Downloading supervision-0.10.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.16)\n",
            "Collecting wget (from roboflow)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.1.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.40.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (2.0.12)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=52cfed0d38fa75a8ac88e1742f5e950f8472467bfc9d6917786ee0bb08d4eb14\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, python-dotenv, pyparsing, idna, cycler, certifi, supervision, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.0\n",
            "    Uninstalling pyparsing-3.1.0:\n",
            "      Successfully uninstalled pyparsing-3.1.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.5.7\n",
            "    Uninstalling certifi-2023.5.7:\n",
            "      Successfully uninstalled certifi-2023.5.7\n",
            "Successfully installed certifi-2022.12.7 cycler-0.10.0 idna-2.10 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-1.0.0 roboflow-1.1.0 supervision-0.10.0 wget-3.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "cycler",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Roboflow datasets are used in this notebook \n",
        "!pip install roboflow\n",
        "from roboflow import Roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwCYIB15t-QD",
        "outputId": "42abf245-2b64-44e2-e458-780d46996907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in American-Sign-Language-Letters-6 to yolov5pytorch: 99% [149381120 / 150626826] bytes"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Dataset Version Zip to American-Sign-Language-Letters-6 in yolov5pytorch:: 100%|██████████| 1452/1452 [00:01<00:00, 1331.62it/s]\n"
          ]
        }
      ],
      "source": [
        "# Connect to Roboflow website using your account's workspace private API\n",
        "rf = Roboflow(api_key=\"<your-roboflow-API-key>\")\n",
        "\n",
        "# link to the workspace of dataset wanted\n",
        "project = rf.workspace(\"david-lee-d0rhs\").project(\"american-sign-language-letters\")\n",
        "\n",
        "# download the dataset for yolov5\n",
        "dataset = project.version(6).download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVy8FlS6EBLV",
        "outputId": "8075d05d-d683-4ca0-bcbb-f3307b7eb6bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2047, 1536, 3)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# read a sample from the valid/images, for it's shape details and so on\n",
        "import cv2\n",
        "\n",
        "img = cv2.imread('/content/American-Sign-Language-Letters-6/valid/images/A10_jpg.rf.85a1d5108a4be1e892ed2d1eab546db9.jpg')\n",
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR3K6ldghtXs",
        "outputId": "0b3b4d2b-04c1-4e26-93ca-296e3f75ee18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "more: stat of /content/yolov5/American-Sign-Language-Letters-6/data.yaml failed: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# lets look at the data\n",
        "!more /content/yolov5/American-Sign-Language-Letters-6/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLu3s45b7r7n",
        "outputId": "089aed47-d1f7-4d31-858c-72e7eebd9c95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16008, done.\u001b[K\n",
            "remote: Counting objects: 100% (177/177), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 16008 (delta 109), reused 129 (delta 83), pack-reused 15831\u001b[K\n",
            "Receiving objects: 100% (16008/16008), 14.66 MiB | 20.76 MiB/s, done.\n",
            "Resolving deltas: 100% (10978/10978), done.\n",
            "/content/yolov5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (8.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.10.1)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.65.0)\n",
            "Collecting ultralytics>=8.0.111 (from -r requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.0.123-py3-none-any.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.4/612.4 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.12.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->-r requirements.txt (line 15)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->-r requirements.txt (line 15)) (16.0.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2022.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from cycler>=0.10->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->-r requirements.txt (line 15)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Installing collected packages: smmap, gitdb, gitpython, ultralytics, thop\n",
            "Successfully installed gitdb-4.0.10 gitpython-3.1.31 smmap-5.0.0 thop-0.1.1.post2209072238 ultralytics-8.0.123\n"
          ]
        }
      ],
      "source": [
        "# clone the yolov5 and install all the requirements\n",
        "\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd ./yolov5\n",
        "%pip install -r requirements.txt  # install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FVeXIY9SRs7h"
      },
      "outputs": [],
      "source": [
        "# move the dataset inside yolov5 (can also change the path used by default in the train.py)\n",
        "!mv /content/American-Sign-Language-Letters-6 /content/yolov5/American-Sign-Language-Letters-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VPPL-Lrtd3pH"
      },
      "outputs": [],
      "source": [
        "# Track the weights and biases automatically using wandb \n",
        "# !pip install wandb\n",
        "# !wandb login\n",
        "# import wandb\n",
        "# wandb.init(project=\"YOLOv5-ASL\", entity=\"<your-entity-name>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IMtu2hRoXU7",
        "outputId": "4860f3fc-a445-49e0-bd7f-18231e36b534"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=, data=/content/yolov5/American-Sign-Language-Letters-6/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=10, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-187-g0004c74 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 33.0MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x.pt to yolov5x.pt...\n",
            "100% 166M/166M [00:02<00:00, 65.8MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=26\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1    208599  models.yolo.Detect                      [26, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model summary: 445 layers, 86386039 parameters, 86386039 gradients, 205.2 GFLOPs\n",
            "\n",
            "Transferred 739/745 items from yolov5x.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.00046875), 126 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/American-Sign-Language-Letters-6/train/labels... 504 images, 0 backgrounds, 0 corrupt: 100% 504/504 [00:00<00:00, 851.32it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/American-Sign-Language-Letters-6/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.4GB ram): 100% 504/504 [00:18<00:00, 27.96it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/American-Sign-Language-Letters-6/valid/labels... 144 images, 0 backgrounds, 0 corrupt: 100% 144/144 [00:00<00:00, 726.97it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/American-Sign-Language-Letters-6/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 144/144 [00:09<00:00, 15.72it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.31 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/49      9.27G    0.07721    0.03057    0.07445          9        640: 100% 51/51 [00:39<00:00,  1.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:04<00:00,  1.91it/s]\n",
            "                   all        144        144    0.00344      0.954      0.055     0.0307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/49      10.2G    0.05102     0.0235    0.07154         14        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.51it/s]\n",
            "                   all        144        144    0.00497       0.98     0.0927     0.0502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/49      10.2G    0.04934    0.01891    0.06945          9        640: 100% 51/51 [00:33<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.39it/s]\n",
            "                   all        144        144    0.00564       0.99     0.0648      0.036\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/49      10.2G    0.04567    0.01528    0.07058          9        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.53it/s]\n",
            "                   all        144        144     0.0701      0.587      0.137      0.095\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/49      10.2G    0.04097    0.01294    0.06771          7        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.56it/s]\n",
            "                   all        144        144     0.0321      0.956      0.161      0.113\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/49      10.2G    0.03692     0.0124    0.06552          8        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.55it/s]\n",
            "                   all        144        144      0.541     0.0973      0.201      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/49      10.2G    0.03424    0.01174    0.06424         12        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.29it/s]\n",
            "                   all        144        144      0.438      0.106      0.205      0.115\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/49      10.2G    0.03748    0.01122    0.06611         16        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.58it/s]\n",
            "                   all        144        144      0.437       0.19      0.224      0.147\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/49      10.2G    0.03227    0.01051    0.06212          7        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.57it/s]\n",
            "                   all        144        144      0.526      0.211      0.303      0.213\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/49      10.2G    0.03076    0.01044    0.05923          7        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.45it/s]\n",
            "                   all        144        144      0.579      0.266      0.301      0.197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/49      10.2G    0.03123    0.01035    0.05868         10        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.60it/s]\n",
            "                   all        144        144      0.423      0.381      0.331      0.204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/49      10.2G    0.03065     0.0102     0.0544          9        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.58it/s]\n",
            "                   all        144        144      0.369      0.394       0.35      0.252\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/49      10.2G    0.03123    0.01038    0.05611         11        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.57it/s]\n",
            "                   all        144        144      0.387      0.349      0.336      0.247\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/49      10.2G    0.03067   0.009775    0.05568          6        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.59it/s]\n",
            "                   all        144        144      0.352      0.474      0.383      0.283\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/49      10.2G    0.02792     0.0102    0.05322         12        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.51it/s]\n",
            "                   all        144        144      0.413      0.453       0.42      0.335\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/49      10.2G    0.02637   0.009445    0.05551         10        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.34it/s]\n",
            "                   all        144        144      0.379      0.514      0.508      0.357\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/49      10.2G    0.02774   0.009644     0.0505         11        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.38it/s]\n",
            "                   all        144        144       0.37      0.577      0.496      0.397\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/49      10.2G    0.03145   0.009485    0.05208         13        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.50it/s]\n",
            "                   all        144        144      0.411        0.6      0.497      0.402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/49      10.2G    0.02461   0.008981    0.05027         11        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.34it/s]\n",
            "                   all        144        144      0.468      0.511      0.516      0.401\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/49      10.2G    0.02365   0.009318     0.0493         11        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.46it/s]\n",
            "                   all        144        144       0.35      0.669      0.547      0.426\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/49      10.2G    0.02749   0.009507     0.0492          7        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.56it/s]\n",
            "                   all        144        144      0.432      0.635      0.578       0.47\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/49      10.2G    0.02629   0.009567    0.04644          9        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.47it/s]\n",
            "                   all        144        144      0.434      0.594      0.564      0.495\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/49      10.2G    0.02686   0.009543    0.04786         10        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.47it/s]\n",
            "                   all        144        144      0.532      0.557      0.608      0.489\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/49      10.2G     0.0268   0.008925    0.04832          4        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.60it/s]\n",
            "                   all        144        144      0.592      0.553      0.605      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/49      10.2G    0.02534   0.008609    0.04858         10        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.40it/s]\n",
            "                   all        144        144      0.573      0.601      0.638      0.519\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/49      10.2G    0.02565    0.00835    0.04774         13        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.33it/s]\n",
            "                   all        144        144      0.389      0.709       0.64      0.528\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/49      10.2G     0.0246   0.008806    0.04134          8        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.38it/s]\n",
            "                   all        144        144      0.428      0.685       0.65      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/49      10.2G    0.02404   0.009169    0.04113         12        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.33it/s]\n",
            "                   all        144        144      0.436      0.732      0.674      0.544\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/49      10.2G    0.02412   0.009313     0.0419         14        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.45it/s]\n",
            "                   all        144        144      0.404      0.739      0.701      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/49      10.2G    0.02238   0.008486    0.04193         10        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.44it/s]\n",
            "                   all        144        144      0.488       0.79      0.738      0.643\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/49      10.2G    0.02249   0.008859    0.04078         10        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.37it/s]\n",
            "                   all        144        144      0.486      0.775      0.724      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/49      10.2G    0.02259   0.008295    0.03961         11        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.52it/s]\n",
            "                   all        144        144       0.51       0.76      0.764      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/49      10.2G    0.02215   0.008348    0.03914         11        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.58it/s]\n",
            "                   all        144        144      0.566       0.75       0.78      0.647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/49      10.2G     0.0225   0.008438    0.03692          7        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.54it/s]\n",
            "                   all        144        144      0.666      0.749      0.806      0.689\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/49      10.2G    0.02104   0.008024    0.03921         11        640: 100% 51/51 [00:33<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.50it/s]\n",
            "                   all        144        144      0.618      0.838      0.822      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/49      10.2G    0.02021   0.008003    0.03619         10        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.57it/s]\n",
            "                   all        144        144      0.649      0.767      0.807      0.691\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/49      10.2G    0.02008   0.007936    0.03531          7        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.43it/s]\n",
            "                   all        144        144      0.668      0.804      0.839      0.741\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/49      10.2G    0.01914   0.008373    0.03382         14        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.37it/s]\n",
            "                   all        144        144      0.704      0.788      0.819      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/49      10.2G    0.01933   0.007913     0.0326          8        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.40it/s]\n",
            "                   all        144        144      0.702        0.8       0.83       0.73\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/49      10.2G    0.01911   0.008086    0.03586         10        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.57it/s]\n",
            "                   all        144        144      0.775      0.801      0.865       0.75\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/49      10.2G    0.01812   0.007699    0.03187          6        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.50it/s]\n",
            "                   all        144        144      0.738      0.817      0.867      0.753\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/49      10.2G    0.01942   0.008031    0.03164          9        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.39it/s]\n",
            "                   all        144        144      0.738      0.844      0.866      0.763\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/49      10.2G    0.01732    0.00721    0.03097          8        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.51it/s]\n",
            "                   all        144        144       0.79      0.843      0.895      0.807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/49      10.2G    0.01614   0.007689    0.02833         14        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.36it/s]\n",
            "                   all        144        144      0.773       0.86      0.901      0.817\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/49      10.2G    0.01575   0.007215    0.02714          7        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.35it/s]\n",
            "                   all        144        144      0.765      0.846      0.896      0.807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/49      10.2G    0.01597   0.007461    0.02989         12        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.39it/s]\n",
            "                   all        144        144      0.782      0.834      0.905      0.829\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/49      10.2G    0.01551   0.007357     0.0306         12        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.45it/s]\n",
            "                   all        144        144      0.823       0.83      0.911      0.838\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/49      10.2G    0.01682   0.007113    0.02873         13        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.48it/s]\n",
            "                   all        144        144      0.857      0.827       0.91      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/49      10.2G    0.01562    0.00766    0.03105         11        640: 100% 51/51 [00:32<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.56it/s]\n",
            "                   all        144        144      0.831      0.832      0.909      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/49      10.2G    0.01383   0.007195    0.02688          4        640: 100% 51/51 [00:32<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:03<00:00,  2.45it/s]\n",
            "                   all        144        144      0.803      0.822      0.911      0.852\n",
            "\n",
            "50 epochs completed in 0.600 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 173.4MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 173.4MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86341639 parameters, 0 gradients, 204.3 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 8/8 [00:06<00:00,  1.26it/s]\n",
            "                   all        144        144      0.803      0.822      0.911      0.852\n",
            "                     A        144          5      0.644        0.6      0.765      0.765\n",
            "                     B        144          9      0.924      0.667      0.962      0.891\n",
            "                     C        144          3      0.905          1      0.995      0.929\n",
            "                     D        144          6       0.84      0.881      0.972      0.905\n",
            "                     E        144          4      0.873          1      0.995      0.964\n",
            "                     F        144          8      0.949          1      0.995      0.935\n",
            "                     G        144          5      0.416          1      0.995      0.935\n",
            "                     H        144          9      0.908      0.889      0.984      0.939\n",
            "                     I        144          2      0.603        0.5      0.509      0.509\n",
            "                     J        144          8      0.936          1      0.995      0.743\n",
            "                     K        144          6      0.854      0.667      0.893      0.846\n",
            "                     L        144          4       0.75          1      0.995      0.995\n",
            "                     M        144          8          1      0.421       0.94       0.84\n",
            "                     N        144          4      0.411       0.25      0.428      0.423\n",
            "                     O        144          7      0.859          1      0.995      0.931\n",
            "                     P        144          7      0.951          1      0.995      0.887\n",
            "                     Q        144          4      0.903          1      0.995      0.859\n",
            "                     R        144          7      0.834          1      0.995      0.954\n",
            "                     S        144          4      0.839          1      0.995      0.995\n",
            "                     T        144          6          1          0      0.512      0.488\n",
            "                     U        144          7      0.837      0.714      0.924      0.846\n",
            "                     V        144          5       0.73        0.8      0.895      0.851\n",
            "                     W        144          3       0.47          1      0.995      0.951\n",
            "                     X        144          1      0.672          1      0.995      0.895\n",
            "                     Y        144          8      0.886      0.978      0.982      0.903\n",
            "                     Z        144          4      0.875          1      0.995       0.97\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# best and last model weights are saved automatically and all the epochs results are also saved in runs/exp{number} folder of yolov5\n",
        "\n",
        "# train the yolov5 model from scratch\n",
        "# !python train.py --img 640 --batch 10 --epochs 50 --data /content/yolov5/American-Sign-Language-Letters-6/data.yaml --weights '' --cfg yolov5x.yaml --cache ram\n",
        "# since the dataset is not that large, lets use transfer learning\n",
        "\n",
        "# train the yolov5 model from pretrained weights\n",
        "!python train.py --img 640 --batch 10 --epochs 50 --data /content/yolov5/American-Sign-Language-Letters-6/data.yaml --weights yolov5x.pt --cache ram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqXX0VYgsD24",
        "outputId": "33b5a4f9-9d8d-4bf7-ccc1-018bcf645f83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/yolov5/runs/train/exp/ (stored 0%)\n",
            "  adding: content/yolov5/runs/train/exp/confusion_matrix.png (deflated 15%)\n",
            "  adding: content/yolov5/runs/train/exp/val_batch0_pred.jpg (deflated 10%)\n",
            "  adding: content/yolov5/runs/train/exp/opt.yaml (deflated 48%)\n",
            "  adding: content/yolov5/runs/train/exp/labels_correlogram.jpg (deflated 41%)\n",
            "  adding: content/yolov5/runs/train/exp/P_curve.png (deflated 10%)\n",
            "  adding: content/yolov5/runs/train/exp/events.out.tfevents.1687864777.a950a6fc5192.938.0 (deflated 32%)\n",
            "  adding: content/yolov5/runs/train/exp/results.png (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/exp/val_batch1_pred.jpg (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/exp/labels.jpg (deflated 34%)\n",
            "  adding: content/yolov5/runs/train/exp/results.csv (deflated 82%)\n",
            "  adding: content/yolov5/runs/train/exp/train_batch2.jpg (deflated 12%)\n",
            "  adding: content/yolov5/runs/train/exp/val_batch0_labels.jpg (deflated 10%)\n",
            "  adding: content/yolov5/runs/train/exp/train_batch0.jpg (deflated 11%)\n",
            "  adding: content/yolov5/runs/train/exp/val_batch1_labels.jpg (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/exp/val_batch2_labels.jpg (deflated 9%)\n",
            "  adding: content/yolov5/runs/train/exp/hyp.yaml (deflated 45%)\n",
            "  adding: content/yolov5/runs/train/exp/PR_curve.png (deflated 20%)\n",
            "  adding: content/yolov5/runs/train/exp/val_batch2_pred.jpg (deflated 9%)\n",
            "  adding: content/yolov5/runs/train/exp/R_curve.png (deflated 10%)\n",
            "  adding: content/yolov5/runs/train/exp/weights/ (stored 0%)\n",
            "  adding: content/yolov5/runs/train/exp/weights/last.pt (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/exp/weights/best.pt (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/exp/F1_curve.png (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/exp/train_batch1.jpg (deflated 11%)\n"
          ]
        }
      ],
      "source": [
        "# Zip the YOLOv5 folder in order to download it\n",
        "# !zip -r /content/yolov5.zip /content/yolov5\n",
        "!zip -r /content/yolov5x_pretrained.zip /content/yolov5/runs/train/exp\n",
        "\n",
        "\n",
        "# and download manually:\n",
        "#   * 'README.robotflow.txt'\n",
        "#   * 'data.yaml'\n",
        "#   * 'yolov5.zip'\n",
        "#   * 'yolov5s.pt'\n",
        "#   * this notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C9XCza2KMP2"
      },
      "outputs": [],
      "source": [
        "# from utils.plots import plot_results\n",
        "# # plot 'results.csv' as 'results.png'\n",
        "# plot_results('/content/yolov5/runs/train/exp10/results.csv') \n",
        "# # will already be there in the '/conent/yolov5/runs/train/exp10' as 'results.png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "634Z6H7pKMJo"
      },
      "outputs": [],
      "source": [
        "# # One feature that many people don't know about though is that you can still overlay multiple results by placing multiple results.csv files in a single directory dir and then:\n",
        "\n",
        "# from utils.plots import *; plot_results(dir='path/to/dir')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRO5GXQ8sF6F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EHRq3rKGx5I"
      },
      "outputs": [],
      "source": [
        "# !python train.py --resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHuTX_jwJAXK",
        "outputId": "be2dcb27-64ae-47be-8fe4-40d2d72fbef6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=data/coco128.yaml, weights=['yolov5x.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['torchscript', 'pb']\n",
            "YOLOv5 🚀 v7.0-187-g0004c74 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5x summary: 444 layers, 86705005 parameters, 0 gradients\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov5x.pt with output shape (1, 25200, 85) (166.0 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.0.1+cu118...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ✅ 19.2s, saved as yolov5x.torchscript (331.6 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.12.0...\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "2023-06-27 12:00:00.047711: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  1    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  1   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1  1  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  1  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1    571965  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280], [640, 640]]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(1, 640, 640, 3)]   0           []                               \n",
            "                                                                                                  \n",
            " tf_conv (TFConv)               (1, 320, 320, 80)    8720        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf_conv_1 (TFConv)             (1, 160, 160, 160)   115360      ['tf_conv[0][0]']                \n",
            "                                                                                                  \n",
            " tfc3 (TFC3)                    (1, 160, 160, 160)   308160      ['tf_conv_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_13 (TFConv)            (1, 80, 80, 320)     461120      ['tfc3[0][0]']                   \n",
            "                                                                                                  \n",
            " tfc3_1 (TFC3)                  (1, 80, 80, 320)     2256000     ['tf_conv_13[0][0]']             \n",
            "                                                                                                  \n",
            " tf_conv_33 (TFConv)            (1, 40, 40, 640)     1843840     ['tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_2 (TFC3)                  (1, 40, 40, 640)     13116160    ['tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tf_conv_61 (TFConv)            (1, 20, 20, 1280)    7374080     ['tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_3 (TFC3)                  (1, 20, 20, 1280)    19668480    ['tf_conv_61[0][0]']             \n",
            "                                                                                                  \n",
            " tfsppf (TFSPPF)                (1, 20, 20, 1280)    4097920     ['tfc3_3[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_conv_75 (TFConv)            (1, 20, 20, 640)     819840      ['tfsppf[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample (TFUpsample)       (1, 40, 40, 640)     0           ['tf_conv_75[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat (TFConcat)           (1, 40, 40, 1280)    0           ['tf_upsample[0][0]',            \n",
            "                                                                  'tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_4 (TFC3)                  (1, 40, 40, 640)     5328640     ['tf_concat[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_87 (TFConv)            (1, 40, 40, 320)     205120      ['tfc3_4[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample_1 (TFUpsample)     (1, 80, 80, 320)     0           ['tf_conv_87[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat_1 (TFConcat)         (1, 80, 80, 640)     0           ['tf_upsample_1[0][0]',          \n",
            "                                                                  'tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_5 (TFC3)                  (1, 80, 80, 320)     1333120     ['tf_concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_99 (TFConv)            (1, 40, 40, 320)     921920      ['tfc3_5[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_2 (TFConcat)         (1, 40, 40, 640)     0           ['tf_conv_99[0][0]',             \n",
            "                                                                  'tf_conv_87[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_6 (TFC3)                  (1, 40, 40, 640)     4919040     ['tf_concat_2[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_111 (TFConv)           (1, 20, 20, 640)     3687040     ['tfc3_6[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_3 (TFConcat)         (1, 20, 20, 1280)    0           ['tf_conv_111[0][0]',            \n",
            "                                                                  'tf_conv_75[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_7 (TFC3)                  (1, 20, 20, 1280)    19668480    ['tf_concat_3[0][0]']            \n",
            "                                                                                                  \n",
            " tf_detect (TFDetect)           ((1, 25200, 85),     571965      ['tfc3_5[0][0]',                 \n",
            "                                )                                 'tfc3_6[0][0]',                 \n",
            "                                                                  'tfc3_7[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 86,705,005\n",
            "Trainable params: 0\n",
            "Non-trainable params: 86,705,005\n",
            "__________________________________________________________________________________________________\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 39.0s, saved as yolov5x_saved_model (331.2 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m starting export with tensorflow 2.12.0...\n",
            "\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m export success ✅ 11.3s, saved as yolov5x.pb (331.2 MB)\n",
            "\n",
            "Export complete (80.7s)\n",
            "Results saved to \u001b[1m/content/yolov5\u001b[0m\n",
            "Detect:          python detect.py --weights yolov5x.pb \n",
            "Validate:        python val.py --weights yolov5x.pb \n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5x.pb')  \n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ],
      "source": [
        "# save yolov5x.pt (weights after training and also include the model yolov5x.pb)\n",
        "!python /content/yolov5/export.py --weights yolov5x.pt --include torchscript pb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPsaMIBtF_Sd"
      },
      "outputs": [],
      "source": [
        "# # include torchscript for the best model weights of all the epochs in the experiment (also weights are automatically saved in the yolov5/runs/exp folder)\n",
        "# !python /content/yolov5/export.py --weights yolov5x.pt --include torchscript pb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGb66KthLwi6"
      },
      "outputs": [],
      "source": [
        "# copy the yolov5 folder to drive\n",
        "!cp /content/yolov5 /content/drive/MyDrive/ML_Proj -r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXTHJUZHMoED",
        "outputId": "90c0e030-a9fe-4e72-fcc2-a4d533b02859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W&B offline. Running your script from this directory will only write metadata locally. Use wandb disabled to completely turn off W&B.\n"
          ]
        }
      ],
      "source": [
        "# !wandb offline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx7JqdcPD9VJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
